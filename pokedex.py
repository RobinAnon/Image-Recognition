# -*- coding: utf-8 -*-
"""Pokedex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nAdu9hlbsFkhEPS9WUXhl0_aIQCpbuRV
"""

### Cell 1 ###
!pip3 install kaggle
!pip3 install kaggle-cli


### Cell 2 ###
!touch kaggle.json
!echo '{"username":"robinconvert","key":""}' > kaggle.json
!mv ./kaggle.json ~/.kaggle/kaggle.json


### Cell 4 ###
!kaggle datasets download -d ankitesh97/pokemon-images --unzip

!tar -zxf pokemon.tar.gz

#!ls


### Cell 5 ###
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt 

def affiche_pokemon(pokemon):
  imgpil = Image.open(pokemon)  
  img = np.asarray(imgpil)
  plt.imshow(img)
  plt.show()


### Cell 6 ###
!ls


### Cell 7 ###
import glob

mespokemon=glob.glob('pokemon/*')

affiche_pokemon(mespokemon[11])


### Cell 8 ###
import random
random.shuffle(mespokemon)


### Cell 9 ###
import re

def recupere_numero_pokemon(pokemon):
  
  list_num=pokemon.split("_")
  if(len(list_num[-1])>3):
    num=list_num[-1].split("-")
    res=num[0]
  else:
    res=list_num[-1]
  return re.findall("([0-9]+)", res)


### Cell 10 ###
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]

index_split=int(len(mespokemon)*0.75)

for i in range(index_split):
  #X_train+=[mespokemon[i]]
  Y_train+=[int(recupere_numero_pokemon(mespokemon[i])[0])]
  
  imgpil = Image.open(mespokemon[i])  
  img = np.asarray(imgpil)
  X_train+=[img/255.0]
    

for i in range(index_split,len(mespokemon)):
  #X_test+=[mespokemon[i]]
  Y_test+=[int(recupere_numero_pokemon(mespokemon[i])[0])]
  
  imgpil = Image.open(mespokemon[i])  
  img = np.asarray(imgpil)
  X_test+=[img/255.0]

  
X_train=np.asarray(X_train)
Y_train=np.asarray(Y_train)
X_test=np.asarray(X_test)
Y_test=np.asarray(Y_test)


### Cell 11 ###
len(Y_train)


### Cell 12 ###
X_train[0]
Y_train


Vrai_Y_train=[]

for i in range(len(Y_train)):
  L=[]
  for j in range(721):
    L+=[0]
  L[Y_train[i]-1]=1
  Vrai_Y_train+=[L]


### Cell 13 ###
Vrai_Y_test=[]

for i in range(len(Y_test)):
  L=[]
  for j in range(721):
    L+=[0]
  L[Y_test[i]-1]=1
  Vrai_Y_test+=[L]


### Cell 14 ###
Y_train=np.asarray(Vrai_Y_train)
Y_test=np.asarray(Vrai_Y_test)


### Cell 15 ###
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline 
#car notebook

from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Flatten, Dense, Dropout
#dropout limite l'overfitting 

from tensorflow.keras.models import Sequential

from tensorflow.keras.optimizers import Adam
#optimiser pour la backpropagation


### Cell 16 ###
VGG_CONVS = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))
for layer in VGG_CONVS.layers:
  layer.trainable= False


### Cell 17 ###
import tensorflow as tf
from tensorflow import keras
model = keras.Sequential([
    VGG_CONVS,
    keras.layers.Flatten(),
    keras.layers.Dense(1024, activation=tf.nn.relu),
    keras.layers.Dense(721, activation=tf.nn.softmax)
])

model.compile(optimizer=tf.train.AdamOptimizer(), 
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history=model.fit(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test))


### Cell 18 ###
# Plot loss (left) and accuracy (right)
plt.figure(figsize=(19, 10))

# training loss and validation loss
plt.subplot(121)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

# training accuracy and validation accuracy
plt.subplot(122)
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')


plt.show()


### Cell 19 ###
y_ = model.predict(np.array([X_test[159]]))
print(np.argmax(y_)+1)


### Cell 20 ###
print(np.argmax(Y_test[159])+1)
plt.imshow(X_test[159])
plt.show()


### Cell 21 ###
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout
model2 = Sequential()

#add model layers
model2.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(128,128,3)))
model2.add(MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))

model2.add(Conv2D(64, kernel_size=3, activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))

model2.add(Conv2D(32, kernel_size=3, activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))

model2.add(Conv2D(16, kernel_size=3, activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))

model2.add(Flatten())
model2.add(Dense(1024, activation='relu'))
model2.add(Dropout(0.3))
model2.add(Dense(721, activation='softmax'))


model2.compile(optimizer=tf.train.AdamOptimizer(), 
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history=model2.fit(X_train, Y_train, epochs=250, validation_data=(X_test, Y_test))


### Cell 22 ###
# Plot loss (left) and accuracy (right)
plt.figure(figsize=(19, 10))

# training loss and validation loss
plt.subplot(121)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

# training accuracy and validation accuracy
plt.subplot(122)
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')


plt.show()
